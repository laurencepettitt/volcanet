Train for 213 steps, validate for 6 steps
Epoch 1/100
213/213 [==============================] - 9s 44ms/step - loss: 0.6418 - cat_acc: 0.8531 - val_loss: 0.5790 - val_cat_acc: 0.8594
Epoch 2/100
213/213 [==============================] - 7s 34ms/step - loss: 0.5272 - cat_acc: 0.8592 - val_loss: 0.3892 - val_cat_acc: 0.8698
Epoch 3/100
213/213 [==============================] - 8s 36ms/step - loss: 0.3464 - cat_acc: 0.8885 - val_loss: 0.3283 - val_cat_acc: 0.8750
Epoch 4/100
213/213 [==============================] - 7s 33ms/step - loss: 0.3066 - cat_acc: 0.8989 - val_loss: 0.2993 - val_cat_acc: 0.8802
Epoch 5/100
213/213 [==============================] - 7s 35ms/step - loss: 0.2816 - cat_acc: 0.9045 - val_loss: 0.3044 - val_cat_acc: 0.8906
Epoch 6/100
213/213 [==============================] - 7s 34ms/step - loss: 0.2745 - cat_acc: 0.9076 - val_loss: 0.2656 - val_cat_acc: 0.9271
Epoch 7/100
213/213 [==============================] - 7s 33ms/step - loss: 0.2564 - cat_acc: 0.9130 - val_loss: 0.2775 - val_cat_acc: 0.9219
Epoch 8/100
213/213 [==============================] - 7s 34ms/step - loss: 0.2515 - cat_acc: 0.9129 - val_loss: 0.2612 - val_cat_acc: 0.9219
Epoch 9/100
213/213 [==============================] - 7s 33ms/step - loss: 0.2291 - cat_acc: 0.9186 - val_loss: 0.2544 - val_cat_acc: 0.9167
Epoch 10/100
213/213 [==============================] - 7s 35ms/step - loss: 0.2143 - cat_acc: 0.9244 - val_loss: 0.2835 - val_cat_acc: 0.9115
Epoch 11/100
213/213 [==============================] - 7s 34ms/step - loss: 0.2223 - cat_acc: 0.9206 - val_loss: 0.2419 - val_cat_acc: 0.9219
Epoch 12/100
213/213 [==============================] - 8s 39ms/step - loss: 0.2047 - cat_acc: 0.9265 - val_loss: 0.2478 - val_cat_acc: 0.9323
Epoch 13/100
213/213 [==============================] - 8s 36ms/step - loss: 0.2035 - cat_acc: 0.9294 - val_loss: 0.2298 - val_cat_acc: 0.9271
Epoch 14/100
213/213 [==============================] - 7s 34ms/step - loss: 0.1963 - cat_acc: 0.9310 - val_loss: 0.2360 - val_cat_acc: 0.9323
Epoch 15/100
213/213 [==============================] - 7s 34ms/step - loss: 0.1884 - cat_acc: 0.9325 - val_loss: 0.2331 - val_cat_acc: 0.9219
Epoch 16/100
213/213 [==============================] - 8s 37ms/step - loss: 0.1899 - cat_acc: 0.9315 - val_loss: 0.2373 - val_cat_acc: 0.9219
Epoch 17/100
213/213 [==============================] - 7s 35ms/step - loss: 0.1774 - cat_acc: 0.9354 - val_loss: 0.2232 - val_cat_acc: 0.9167
Epoch 18/100
213/213 [==============================] - 7s 34ms/step - loss: 0.1749 - cat_acc: 0.9347 - val_loss: 0.2190 - val_cat_acc: 0.9219
Epoch 19/100
213/213 [==============================] - 7s 34ms/step - loss: 0.1674 - cat_acc: 0.9387 - val_loss: 0.2232 - val_cat_acc: 0.9271
Epoch 20/100
213/213 [==============================] - 8s 35ms/step - loss: 0.1591 - cat_acc: 0.9425 - val_loss: 0.2200 - val_cat_acc: 0.9271
Epoch 21/100
213/213 [==============================] - 7s 33ms/step - loss: 0.1551 - cat_acc: 0.9434 - val_loss: 0.2501 - val_cat_acc: 0.9323
Epoch 22/100
213/213 [==============================] - 8s 35ms/step - loss: 0.1539 - cat_acc: 0.9447 - val_loss: 0.2377 - val_cat_acc: 0.9323
Epoch 23/100
213/213 [==============================] - 7s 34ms/step - loss: 0.1496 - cat_acc: 0.9460 - val_loss: 0.2559 - val_cat_acc: 0.9219
Epoch 24/100
213/213 [==============================] - 7s 34ms/step - loss: 0.1446 - cat_acc: 0.9485 - val_loss: 0.2419 - val_cat_acc: 0.9167
Epoch 25/100
213/213 [==============================] - 8s 36ms/step - loss: 0.1326 - cat_acc: 0.9523 - val_loss: 0.2419 - val_cat_acc: 0.9323
Epoch 26/100
213/213 [==============================] - 10s 48ms/step - loss: 0.1275 - cat_acc: 0.9545 - val_loss: 0.2392 - val_cat_acc: 0.9219
Epoch 27/100
213/213 [==============================] - 7s 35ms/step - loss: 0.1209 - cat_acc: 0.9566 - val_loss: 0.2729 - val_cat_acc: 0.9219
Epoch 28/100
213/213 [==============================] - 7s 34ms/step - loss: 0.1165 - cat_acc: 0.9570 - val_loss: 0.3364 - val_cat_acc: 0.9115
Epoch 29/100
213/213 [==============================] - 7s 35ms/step - loss: 0.1084 - cat_acc: 0.9616 - val_loss: 0.3326 - val_cat_acc: 0.9271
Epoch 30/100
213/213 [==============================] - 7s 34ms/step - loss: 0.0966 - cat_acc: 0.9635 - val_loss: 0.3287 - val_cat_acc: 0.9167
Epoch 31/100
213/213 [==============================] - 7s 33ms/step - loss: 0.0969 - cat_acc: 0.9635 - val_loss: 0.3632 - val_cat_acc: 0.9167
Epoch 32/100
210/213 [============================>.] - ETA: 0s - loss: 0.0866 - cat_acc: 0.9664Restoring model weights from the end of the best epoch.
213/213 [==============================] - 7s 34ms/step - loss: 0.0873 - cat_acc: 0.9661 - val_loss: 0.3352 - val_cat_acc: 0.9167
Epoch 00032: early stopping
Model: "volcanet-cnn"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lambda (Lambda)              (32, 44, 44, 1)           0         
_________________________________________________________________
conv2d (Conv2D)              (32, 42, 42, 16)          160       
_________________________________________________________________
activation (Activation)      (32, 42, 42, 16)          0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (32, 21, 21, 16)          0         
_________________________________________________________________
conv2d_1 (Conv2D)            (32, 19, 19, 32)          4640      
_________________________________________________________________
activation_1 (Activation)    (32, 19, 19, 32)          0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (32, 9, 9, 32)            0         
_________________________________________________________________
flatten (Flatten)            (32, 2592)                0         
_________________________________________________________________
dense (Dense)                (32, 64)                  165952    
_________________________________________________________________
activation_2 (Activation)    (32, 64)                  0         
_________________________________________________________________
dense_1 (Dense)              (32, 32)                  2080      
_________________________________________________________________
activation_3 (Activation)    (32, 32)                  0         
_________________________________________________________________
output (Dense)               (32, 5)                   165       
_________________________________________________________________
activation_4 (Activation)    (32, 5)                   0         
=================================================================
Total params: 172,997
Trainable params: 172,997
Non-trainable params: 0
_________________________________________________________________
None
85/85 [==============================] - 1s 17ms/step - loss: 0.2512 - cat_acc: 0.9180
test: 0.9180147051811218
218/218 [==============================] - 4s 20ms/step - loss: 0.2027 - cat_acc: 0.9286
train: 0.9286124110221863
