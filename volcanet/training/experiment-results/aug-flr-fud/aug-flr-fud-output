Train for 209 steps, validate for 10 steps
Epoch 1/100
209/209 [==============================] - 31s 149ms/step - loss: 1.5344 - cat_acc: 0.2901 - val_loss: 1.1116 - val_cat_acc: 0.7937
Epoch 2/100
209/209 [==============================] - 10s 50ms/step - loss: 1.3275 - cat_acc: 0.4252 - val_loss: 0.8508 - val_cat_acc: 0.7719
Epoch 3/100
209/209 [==============================] - 9s 45ms/step - loss: 1.2407 - cat_acc: 0.4578 - val_loss: 0.6396 - val_cat_acc: 0.8562
Epoch 4/100
209/209 [==============================] - 13s 61ms/step - loss: 1.1813 - cat_acc: 0.4825 - val_loss: 0.5353 - val_cat_acc: 0.8781
Epoch 5/100
209/209 [==============================] - 9s 44ms/step - loss: 1.1235 - cat_acc: 0.5254 - val_loss: 0.5368 - val_cat_acc: 0.8656
Epoch 6/100
209/209 [==============================] - 9s 43ms/step - loss: 1.0661 - cat_acc: 0.5465 - val_loss: 0.4866 - val_cat_acc: 0.8813
Epoch 7/100
209/209 [==============================] - 9s 44ms/step - loss: 1.0083 - cat_acc: 0.5798 - val_loss: 0.3900 - val_cat_acc: 0.8781
Epoch 8/100
209/209 [==============================] - 9s 43ms/step - loss: 0.9565 - cat_acc: 0.6014 - val_loss: 0.3282 - val_cat_acc: 0.9094
Epoch 9/100
209/209 [==============================] - 9s 43ms/step - loss: 0.8903 - cat_acc: 0.6373 - val_loss: 0.3920 - val_cat_acc: 0.8969
Epoch 10/100
209/209 [==============================] - 9s 43ms/step - loss: 0.8329 - cat_acc: 0.6586 - val_loss: 0.3253 - val_cat_acc: 0.9000
Epoch 11/100
209/209 [==============================] - 9s 43ms/step - loss: 0.7802 - cat_acc: 0.6826 - val_loss: 0.3548 - val_cat_acc: 0.8906
Epoch 12/100
209/209 [==============================] - 9s 43ms/step - loss: 0.7328 - cat_acc: 0.7081 - val_loss: 0.3479 - val_cat_acc: 0.8969
Epoch 13/100
209/209 [==============================] - 9s 44ms/step - loss: 0.6794 - cat_acc: 0.7288 - val_loss: 0.4428 - val_cat_acc: 0.8594
Epoch 14/100
209/209 [==============================] - 9s 44ms/step - loss: 0.6214 - cat_acc: 0.7507 - val_loss: 0.5677 - val_cat_acc: 0.7969
Epoch 15/100
209/209 [==============================] - 9s 43ms/step - loss: 0.5603 - cat_acc: 0.7760 - val_loss: 0.3162 - val_cat_acc: 0.9094
Epoch 16/100
209/209 [==============================] - 9s 43ms/step - loss: 0.4969 - cat_acc: 0.8161 - val_loss: 0.2957 - val_cat_acc: 0.9062
Epoch 17/100
209/209 [==============================] - 9s 42ms/step - loss: 0.4635 - cat_acc: 0.8240 - val_loss: 0.4056 - val_cat_acc: 0.8781
Epoch 18/100
209/209 [==============================] - 10s 46ms/step - loss: 0.4112 - cat_acc: 0.8478 - val_loss: 0.3214 - val_cat_acc: 0.9187
Epoch 19/100
209/209 [==============================] - 9s 45ms/step - loss: 0.3547 - cat_acc: 0.8719 - val_loss: 0.3341 - val_cat_acc: 0.8906
Epoch 20/100
209/209 [==============================] - 10s 46ms/step - loss: 0.3147 - cat_acc: 0.8922 - val_loss: 0.3094 - val_cat_acc: 0.9062
Epoch 21/100
209/209 [==============================] - 10s 48ms/step - loss: 0.2931 - cat_acc: 0.9031 - val_loss: 0.3662 - val_cat_acc: 0.8906
Epoch 22/100
209/209 [==============================] - 9s 42ms/step - loss: 0.2545 - cat_acc: 0.9175 - val_loss: 0.3629 - val_cat_acc: 0.8969
Epoch 23/100
209/209 [==============================] - 9s 42ms/step - loss: 0.2066 - cat_acc: 0.9320 - val_loss: 0.3659 - val_cat_acc: 0.9250
Epoch 24/100
209/209 [==============================] - 9s 41ms/step - loss: 0.1955 - cat_acc: 0.9374 - val_loss: 0.3908 - val_cat_acc: 0.8938
Epoch 25/100
209/209 [==============================] - 9s 43ms/step - loss: 0.1699 - cat_acc: 0.9468 - val_loss: 0.3954 - val_cat_acc: 0.9094
Epoch 26/100
209/209 [==============================] - 9s 45ms/step - loss: 0.1514 - cat_acc: 0.9541 - val_loss: 0.4193 - val_cat_acc: 0.9187
Epoch 27/100
209/209 [==============================] - 9s 42ms/step - loss: 0.1253 - cat_acc: 0.9613 - val_loss: 0.4374 - val_cat_acc: 0.9094
Epoch 28/100
209/209 [==============================] - 13s 61ms/step - loss: 0.1193 - cat_acc: 0.9634 - val_loss: 0.4652 - val_cat_acc: 0.9062
Epoch 29/100
209/209 [==============================] - 9s 43ms/step - loss: 0.1001 - cat_acc: 0.9699 - val_loss: 0.4790 - val_cat_acc: 0.8938
Epoch 30/100
209/209 [==============================] - 12s 59ms/step - loss: 0.0790 - cat_acc: 0.9786 - val_loss: 0.4806 - val_cat_acc: 0.9031
Epoch 31/100
209/209 [==============================] - 9s 45ms/step - loss: 0.0668 - cat_acc: 0.9836 - val_loss: 0.5228 - val_cat_acc: 0.9125
Epoch 32/100
209/209 [==============================] - 9s 43ms/step - loss: 0.0483 - cat_acc: 0.9904 - val_loss: 0.5070 - val_cat_acc: 0.9062
Epoch 33/100
209/209 [==============================] - 9s 43ms/step - loss: 0.0466 - cat_acc: 0.9915 - val_loss: 0.5542 - val_cat_acc: 0.9219
Epoch 34/100
209/209 [==============================] - 9s 43ms/step - loss: 0.0610 - cat_acc: 0.9840 - val_loss: 0.5352 - val_cat_acc: 0.9156
Epoch 35/100
209/209 [==============================] - 9s 43ms/step - loss: 0.0594 - cat_acc: 0.9847 - val_loss: 0.5439 - val_cat_acc: 0.8969
Epoch 36/100
209/209 [==============================] - 12s 58ms/step - loss: 0.0666 - cat_acc: 0.9815 - val_loss: 0.5662 - val_cat_acc: 0.9219
Epoch 37/100
209/209 [==============================] - 12s 59ms/step - loss: 0.0490 - cat_acc: 0.9870 - val_loss: 0.6056 - val_cat_acc: 0.9156
Epoch 38/100
209/209 [==============================] - 10s 50ms/step - loss: 0.0398 - cat_acc: 0.9916 - val_loss: 0.6539 - val_cat_acc: 0.8719
Epoch 39/100
209/209 [==============================] - 10s 49ms/step - loss: 0.1007 - cat_acc: 0.9685 - val_loss: 0.5627 - val_cat_acc: 0.8844
Epoch 40/100
209/209 [==============================] - 9s 43ms/step - loss: 0.0296 - cat_acc: 0.9928 - val_loss: 0.5949 - val_cat_acc: 0.9156
Epoch 41/100
209/209 [==============================] - 9s 43ms/step - loss: 0.0246 - cat_acc: 0.9960 - val_loss: 0.5684 - val_cat_acc: 0.9187
Epoch 42/100
209/209 [==============================] - 9s 43ms/step - loss: 0.0428 - cat_acc: 0.9870 - val_loss: 0.5721 - val_cat_acc: 0.9187
Epoch 43/100
207/209 [============================>.] - ETA: 0s - loss: 0.0170 - cat_acc: 0.9967Restoring model weights from the end of the best epoch.
209/209 [==============================] - 9s 43ms/step - loss: 0.0169 - cat_acc: 0.9967 - val_loss: 0.6020 - val_cat_acc: 0.9156
Epoch 00043: early stopping
Model: "volcanet-cnn"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lambda (Lambda)              (32, 44, 44, 1)           0         
_________________________________________________________________
conv2d (Conv2D)              (32, 42, 42, 16)          160       
_________________________________________________________________
activation (Activation)      (32, 42, 42, 16)          0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (32, 21, 21, 16)          0         
_________________________________________________________________
conv2d_1 (Conv2D)            (32, 19, 19, 32)          4640      
_________________________________________________________________
activation_1 (Activation)    (32, 19, 19, 32)          0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (32, 9, 9, 32)            0         
_________________________________________________________________
flatten (Flatten)            (32, 2592)                0         
_________________________________________________________________
dense (Dense)                (32, 64)                  165952    
_________________________________________________________________
activation_2 (Activation)    (32, 64)                  0         
_________________________________________________________________
dense_1 (Dense)              (32, 32)                  2080      
_________________________________________________________________
activation_3 (Activation)    (32, 32)                  0         
_________________________________________________________________
output (Dense)               (32, 5)                   165       
_________________________________________________________________
activation_4 (Activation)    (32, 5)                   0         
=================================================================
Total params: 172,997
Trainable params: 172,997
Non-trainable params: 0
_________________________________________________________________
None
85/85 [==============================] - 2s 19ms/step - loss: 0.4518 - cat_acc: 0.9029
test: 0.9029411673545837
218/218 [==============================] - 5s 23ms/step - loss: 0.1073 - cat_acc: 0.9713
train: 0.9713302850723267
