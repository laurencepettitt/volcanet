Train for 213 steps, validate for 6 steps
Epoch 1/100
213/213 [==============================] - 45s 210ms/step - loss: 0.6153 - cat_acc: 0.8571 - val_loss: 0.5856 - val_cat_acc: 0.8594
Epoch 2/100
213/213 [==============================] - 43s 203ms/step - loss: 0.5870 - cat_acc: 0.8570 - val_loss: 0.5709 - val_cat_acc: 0.8542
Epoch 3/100
213/213 [==============================] - 41s 194ms/step - loss: 0.5441 - cat_acc: 0.8568 - val_loss: 0.6395 - val_cat_acc: 0.8594
Epoch 4/100
213/213 [==============================] - 42s 199ms/step - loss: 0.4292 - cat_acc: 0.8659 - val_loss: 0.3676 - val_cat_acc: 0.8646
Epoch 5/100
213/213 [==============================] - 42s 198ms/step - loss: 0.3385 - cat_acc: 0.8873 - val_loss: 0.2822 - val_cat_acc: 0.8906
Epoch 6/100
213/213 [==============================] - 44s 207ms/step - loss: 0.3103 - cat_acc: 0.8991 - val_loss: 0.2823 - val_cat_acc: 0.9062
Epoch 7/100
213/213 [==============================] - 52s 242ms/step - loss: 0.2688 - cat_acc: 0.9086 - val_loss: 0.2284 - val_cat_acc: 0.9115
Epoch 8/100
213/213 [==============================] - 39s 183ms/step - loss: 0.2360 - cat_acc: 0.9175 - val_loss: 0.3419 - val_cat_acc: 0.8802
Epoch 9/100
213/213 [==============================] - 39s 181ms/step - loss: 0.2195 - cat_acc: 0.9256 - val_loss: 0.2406 - val_cat_acc: 0.9010
Epoch 10/100
213/213 [==============================] - 40s 188ms/step - loss: 0.1793 - cat_acc: 0.9372 - val_loss: 0.3075 - val_cat_acc: 0.8958
Epoch 11/100
213/213 [==============================] - 46s 215ms/step - loss: 0.1650 - cat_acc: 0.9426 - val_loss: 0.2616 - val_cat_acc: 0.9167
Epoch 12/100
213/213 [==============================] - 41s 194ms/step - loss: 0.1322 - cat_acc: 0.9569 - val_loss: 0.2709 - val_cat_acc: 0.8958
Epoch 13/100
213/213 [==============================] - 39s 182ms/step - loss: 0.1145 - cat_acc: 0.9632 - val_loss: 0.2941 - val_cat_acc: 0.9062
Epoch 14/100
213/213 [==============================] - 42s 195ms/step - loss: 0.0946 - cat_acc: 0.9688 - val_loss: 0.2937 - val_cat_acc: 0.9010
Epoch 15/100
213/213 [==============================] - 43s 203ms/step - loss: 0.0676 - cat_acc: 0.9786 - val_loss: 0.3446 - val_cat_acc: 0.9010
Epoch 16/100
213/213 [==============================] - 43s 203ms/step - loss: 0.0481 - cat_acc: 0.9852 - val_loss: 0.3681 - val_cat_acc: 0.9010
Epoch 17/100
213/213 [==============================] - 43s 203ms/step - loss: 0.0348 - cat_acc: 0.9916 - val_loss: 0.4131 - val_cat_acc: 0.9010
Epoch 18/100
213/213 [==============================] - 42s 197ms/step - loss: 0.0243 - cat_acc: 0.9938 - val_loss: 0.4360 - val_cat_acc: 0.8958
Epoch 19/100
213/213 [==============================] - 42s 199ms/step - loss: 0.0210 - cat_acc: 0.9956 - val_loss: 0.4580 - val_cat_acc: 0.8906
Epoch 20/100
213/213 [==============================] - 43s 200ms/step - loss: 0.0315 - cat_acc: 0.9912 - val_loss: 0.5034 - val_cat_acc: 0.8698
Epoch 21/100
213/213 [==============================] - 43s 203ms/step - loss: 0.0417 - cat_acc: 0.9869 - val_loss: 0.5028 - val_cat_acc: 0.8906
Epoch 22/100
213/213 [==============================] - 43s 200ms/step - loss: 0.0083 - cat_acc: 0.9984 - val_loss: 0.5200 - val_cat_acc: 0.9062
Epoch 23/100
213/213 [==============================] - 42s 195ms/step - loss: 0.0024 - cat_acc: 1.0000 - val_loss: 0.5648 - val_cat_acc: 0.9010
Epoch 24/100
213/213 [==============================] - 41s 195ms/step - loss: 0.0014 - cat_acc: 1.0000 - val_loss: 0.6143 - val_cat_acc: 0.8906
Epoch 25/100
213/213 [==============================] - 41s 195ms/step - loss: 8.8309e-04 - cat_acc: 1.0000 - val_loss: 0.6018 - val_cat_acc: 0.9062
Epoch 26/100
213/213 [==============================] - 42s 196ms/step - loss: 7.0364e-04 - cat_acc: 1.0000 - val_loss: 0.6111 - val_cat_acc: 0.9062
Epoch 27/100
213/213 [==============================] - 42s 197ms/step - loss: 4.8046e-04 - cat_acc: 1.0000 - val_loss: 0.6504 - val_cat_acc: 0.9010
Epoch 28/100
213/213 [==============================] - 44s 206ms/step - loss: 4.0849e-04 - cat_acc: 1.0000 - val_loss: 0.6617 - val_cat_acc: 0.9010
Epoch 29/100
213/213 [==============================] - 40s 187ms/step - loss: 3.2374e-04 - cat_acc: 1.0000 - val_loss: 0.6757 - val_cat_acc: 0.9010
Epoch 30/100
213/213 [==============================] - 40s 189ms/step - loss: 2.6141e-04 - cat_acc: 1.0000 - val_loss: 0.6872 - val_cat_acc: 0.8958
Epoch 31/100
212/213 [============================>.] - ETA: 0s - loss: 2.2740e-04 - cat_acc: 1.0000Restoring model weights from the end of the best epoch.
213/213 [==============================] - 40s 188ms/step - loss: 2.2809e-04 - cat_acc: 1.0000 - val_loss: 0.6979 - val_cat_acc: 0.9010
Epoch 00031: early stopping
Model: "volcanet-cnn"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (32, 108, 108, 16)        160       
_________________________________________________________________
activation (Activation)      (32, 108, 108, 16)        0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (32, 54, 54, 16)          0         
_________________________________________________________________
conv2d_1 (Conv2D)            (32, 52, 52, 32)          4640      
_________________________________________________________________
activation_1 (Activation)    (32, 52, 52, 32)          0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (32, 26, 26, 32)          0         
_________________________________________________________________
flatten (Flatten)            (32, 21632)               0         
_________________________________________________________________
dense (Dense)                (32, 64)                  1384512   
_________________________________________________________________
activation_2 (Activation)    (32, 64)                  0         
_________________________________________________________________
dense_1 (Dense)              (32, 32)                  2080      
_________________________________________________________________
activation_3 (Activation)    (32, 32)                  0         
_________________________________________________________________
output (Dense)               (32, 5)                   165       
_________________________________________________________________
activation_4 (Activation)    (32, 5)                   0         
=================================================================
Total params: 1,391,557
Trainable params: 1,391,557
Non-trainable params: 0
_________________________________________________________________
None
85/85 [==============================] - 5s 59ms/step - loss: 0.3359 - cat_acc: 0.8956
test: 0.895588219165802
218/218 [==============================] - 14s 64ms/step - loss: 0.1370 - cat_acc: 0.9484
train: 0.9483944773674011
